# Adversial-Attacks-on-LLM-Code-Synthesis

# Attacking an LLM code synthesis chain with access to the model
## Injecting bad code onto code synthesis output

# Prompt Injection
# Langchain attacks
https://security.snyk.io/package/pip/langchain
